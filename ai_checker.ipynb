{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb067416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.DataFrame(columns=['id', 'text', 'label'])\n",
    "id = 0\n",
    "\n",
    "# Add to the dataset from the AI-generated essays\n",
    "with open('ai_gen_essays.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    full_texts = [record['full_text'][record['full_text'].index('\\n')+2:] if '\\n' in record['full_text'] else record['full_text'] for record in data]\n",
    "    df = pd.concat([df, pd.DataFrame({'id': range(len(full_texts)), 'text': full_texts, 'label': [0]*len(full_texts)})], ignore_index=True)\n",
    "    \n",
    "# Add to the dataset from the human-written essays\n",
    "human_essays = pd.read_csv('human_essays.csv')\n",
    "full_texts = human_essays['full_text'].tolist()\n",
    "df = pd.concat([df, pd.DataFrame({'id': range(len(full_texts)), 'text': full_texts, 'label': [1]*len(full_texts)})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93b3b4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of essays: 19999\n",
      "AI-generated essays: 2692\n",
      "Human-generated essays: 17307\n",
      "  id                                               text label\n",
      "0  0  In the contemporary world, the art of storytel...     0\n",
      "1  1  As a student at university, I have always been...     0\n",
      "2  2  Stories have the remarkable ability to simplif...     0\n",
      "3  3  As a student and storyteller, I have often fac...     0\n",
      "4  4  As a student at university, I have always been...     0\n"
     ]
    }
   ],
   "source": [
    "# Display info about the dataset\n",
    "print(f'Number of essays: {len(df)}')\n",
    "print(f'AI-generated essays: {len(df[df[\"label\"] == 0])}')\n",
    "print(f'Human-generated essays: {len(df[df[\"label\"] == 1])}')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca8e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15999,)\n",
      "(4000,)\n",
      "(15999,)\n",
      "(4000,)\n",
      "5894    After I read the passage I think Luke really w...\n",
      "3728    I know this wasn't created by aliens in many w...\n",
      "8958    Dear Florida State Senator,\\n\\nThe Electoral C...\n",
      "7671    Although the school system has advanced quite ...\n",
      "5999    Cars are not something that have to be used ev...\n",
      "Name: text, dtype: object\n",
      "5894    1\n",
      "3728    1\n",
      "8958    1\n",
      "7671    1\n",
      "5999    1\n",
      "Name: label, dtype: int64\n",
      "labels in train: {0, 1}\n",
      "type of labels in train: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, random_state=123, stratify=df['label'], shuffle=True)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Print the first 5 rows of the data\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "\n",
    "print(f'labels in train: {set(y_train)}')\n",
    "print(f'type of labels in train: {type(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "becce24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       513\n",
      "           1       1.00      1.00      1.00      3487\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "[[ 513    0]\n",
      " [   0 3487]]\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a TfidfVectorizer object\n",
    "# Set common parameters to limit overfitting in vectorizers\n",
    "max_features = 10000       # Limit vocabulary size\n",
    "min_df = 5                 # Ignore terms that appear in less than 5 documents\n",
    "max_df = 0.8               # Ignore terms that appear in more than 80% of documents\n",
    "vectorizer = TfidfVectorizer(max_features=max_features, min_df=min_df, max_df=max_df)\n",
    "\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the binary classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Print the accuracy of the classifier\n",
    "a_s = accuracy_score(y_test, y_pred)\n",
    "print(\"TfidfVectorizer\")\n",
    "print(\"Accuracy:\", a_s)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the precision, recall, and F1 score\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79f22084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label is: Human\n"
     ]
    }
   ],
   "source": [
    "# Take user input to predict the label of a new essay\n",
    "essay = input(\"Enter the essay to predict the label: \")\n",
    "\n",
    "# Tokenize the essay\n",
    "tokens = vectorizer.transform([essay])\n",
    "\n",
    "# Predict the label of the essay\n",
    "predicted_label = clf.predict(tokens)\n",
    "\n",
    "# Print the predicted label\n",
    "print(f\"The predicted label is: {'Human' if predicted_label[0] == 1 else 'AI'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6501d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping samples in train and test: 0\n"
     ]
    }
   ],
   "source": [
    "overlap = set(X_train).intersection(set(X_test))\n",
    "print(f\"Number of overlapping samples in train and test: {len(overlap)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
